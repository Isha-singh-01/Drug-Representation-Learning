{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:42:30.617262Z",
     "start_time": "2024-04-02T20:42:30.553293200Z"
    }
   },
   "id": "dc429b3ce9fecdf4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pickle\n",
    "from mlm_dataset import MLMDataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:42:43.569910800Z",
     "start_time": "2024-04-02T20:42:30.860367800Z"
    }
   },
   "id": "39e9b34aa096f953"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:42:43.795172900Z",
     "start_time": "2024-04-02T20:42:43.576223Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_model(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.eos_token = tokenizer.sep_token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return list(data)\n",
    "\n",
    "\n",
    "def get_train_test_data(data, split=0.8):\n",
    "    num_examples = len(data)\n",
    "    train_data = data[:int(num_examples * split)]\n",
    "    test_data = data[int(num_examples * split):]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def get_dataset(train_data, test_data, tokenizer):\n",
    "    train_dataset = MLMDataset(train_data, tokenizer)\n",
    "    test_dataset = MLMDataset(test_data, tokenizer)\n",
    "    return {'train': train_dataset, 'test': test_dataset}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Model\")\n",
    "tokenizer, model = init_model(\"bert-base-uncased\")\n",
    "\n",
    "print(\"Loading Data\")\n",
    "data = load_data(\"../kg_paths.pkl\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:47:21.507494700Z",
     "start_time": "2024-04-02T20:47:17.397887800Z"
    }
   },
   "id": "99d1d98645b5f74"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Dataset\")\n",
    "train_data, test_data = get_train_test_data(data)\n",
    "lm_dataset = get_dataset(train_data, test_data, tokenizer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:47:26.984100800Z",
     "start_time": "2024-04-02T20:47:23.878197900Z"
    }
   },
   "id": "de0527f3c402e5e5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(lm_dataset[\"train\"]))['input_ids'].reshape(1, -1).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:47:27.218656Z",
     "start_time": "2024-04-02T20:47:26.988102Z"
    }
   },
   "id": "cdaf1110ee27a74b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"custom_bert_mlm\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, mlm=True, return_tensors='pt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:47:29.145370Z",
     "start_time": "2024-04-02T20:47:28.850154100Z"
    }
   },
   "id": "68fef0495c0d545"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"custom_bert_mlm\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    disable_tqdm=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:47:30.783730500Z",
     "start_time": "2024-04-02T20:47:30.525818300Z"
    }
   },
   "id": "e6d0790529f2d600"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='600000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [     2/600000 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92m<module>\u001B[0m:\u001B[94m9\u001B[0m                                                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 6 \u001B[0m\u001B[2m│   \u001B[0mdata_collator=data_collator,                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 7 \u001B[0m)                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 8 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 9 trainer.train()                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m10 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\transformers\\trainer.py\u001B[0m:\u001B[94m1649\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92mtrain\u001B[0m                                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1646 \u001B[0m\u001B[2m│   │   │   \u001B[0margs=args,                                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1647 \u001B[0m\u001B[2m│   │   │   \u001B[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1648 \u001B[0m\u001B[2m│   │   │   \u001B[0mtrial=trial,                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1649 \u001B[2m│   │   │   \u001B[0mignore_keys_for_eval=ignore_keys_for_eval,                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1650 \u001B[0m\u001B[2m│   │   \u001B[0m)                                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1651 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1652 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_inner_training_loop\u001B[0m(                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\transformers\\trainer.py\u001B[0m:\u001B[94m1938\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92m_inner_training_loop\u001B[0m                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1935 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.control = \u001B[96mself\u001B[0m.callback_handler.on_step_begin(args, \u001B[96mself\u001B[0m.state,  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1936 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1937 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mwith\u001B[0m \u001B[96mself\u001B[0m.accelerator.accumulate(model):                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1938 \u001B[2m│   │   │   │   │   \u001B[0mtr_loss_step = \u001B[96mself\u001B[0m.training_step(model, inputs)                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1939 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1940 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mif\u001B[0m (                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1941 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0margs.logging_nan_inf_filter                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\transformers\\trainer.py\u001B[0m:\u001B[94m2770\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92mtraining_step\u001B[0m                                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2767 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mwith\u001B[0m amp.scale_loss(loss, \u001B[96mself\u001B[0m.optimizer) \u001B[94mas\u001B[0m scaled_loss:                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2768 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mscaled_loss.backward()                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2769 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m2770 \u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m.accelerator.backward(loss)                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2771 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2772 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m loss.detach() / \u001B[96mself\u001B[0m.args.gradient_accumulation_steps                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2773 \u001B[0m                                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\accelerate\\accelerator.py\u001B[0m:\u001B[94m1821\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92mbackward\u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1818 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melif\u001B[0m \u001B[96mself\u001B[0m.scaler \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m:                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1819 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m.scaler.scale(loss).backward(**kwargs)                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1820 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1821 \u001B[2m│   │   │   \u001B[0mloss.backward(**kwargs)                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1822 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1823 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92munscale_gradients\u001B[0m(\u001B[96mself\u001B[0m, optimizer=\u001B[94mNone\u001B[0m):                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1824 \u001B[0m\u001B[2;90m│   │   \u001B[0m\u001B[33m\"\"\"\u001B[0m                                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\torch\\_tensor.py\u001B[0m:\u001B[94m489\u001B[0m in        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[92mbackward\u001B[0m                                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 486 \u001B[0m\u001B[2m│   │   │   │   \u001B[0minputs=inputs,                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 487 \u001B[0m\u001B[2m│   │   │   \u001B[0m)                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 488 \u001B[0m\u001B[2m│   │   \u001B[0mtorch.autograd.backward(                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 489 \u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 490 \u001B[0m\u001B[2m│   │   \u001B[0m)                                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 491 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 492 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mregister_hook\u001B[0m(\u001B[96mself\u001B[0m, hook):                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m:\u001B[94m199\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92mbackward\u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m196 \u001B[0m\u001B[2m│   \u001B[0m\u001B[2m# calls in the traceback and some print out the last line\u001B[0m                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m197 \u001B[0m\u001B[2m│   \u001B[0mVariable._execution_engine.run_backward(  \u001B[2m# Calls into the C++ engine to run the bac\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m198 \u001B[0m\u001B[2m│   │   \u001B[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m199 \u001B[2m│   │   \u001B[0mallow_unreachable=\u001B[94mTrue\u001B[0m, accumulate_grad=\u001B[94mTrue\u001B[0m)  \u001B[2m# Calls into the C++ engine to ru\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m200 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m201 \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mgrad\u001B[0m(                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m202 \u001B[0m\u001B[2m│   \u001B[0moutputs: _TensorOrTensors,                                                             \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mKeyboardInterrupt\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>data_collator=data_collator,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>)                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 9 trainer.train()                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\transformers\\trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1649</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1646 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1647 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1648 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1649 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>ignore_keys_for_eval=ignore_keys_for_eval,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1650 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1651 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1652 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\transformers\\trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1938</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1935 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_step_begin(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1936 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.accumulate(model):                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1938 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1940 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\transformers\\trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2770</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2767 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> amp.scale_loss(loss, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> scaled_loss:                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2768 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>scaled_loss.backward()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2769 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2770 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.backward(loss)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2771 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2772 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss.detach() / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.gradient_accumulation_steps                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2773 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\accelerate\\accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1821</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1818 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1819 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.scale(loss).backward(**kwargs)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1820 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1821 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss.backward(**kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1822 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1823 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unscale_gradients</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, optimizer=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1824 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\torch\\_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">489</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 487 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 489 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 491 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 492 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">register_hook</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, hook):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\mihir\\PycharmProjects\\assignment-2-env\\lib\\site-packages\\torch\\autograd\\__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">199</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>199 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">grad</span>(                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>outputs: _TensorOrTensors,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:48:16.499657700Z",
     "start_time": "2024-04-02T20:47:31.968714300Z"
    }
   },
   "id": "6983bc6fbd34d6d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:46:58.456209200Z",
     "start_time": "2024-04-02T20:46:58.453209500Z"
    }
   },
   "id": "da9401b6694d5443"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aca81560e416987f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
